{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b0160f9",
   "metadata": {},
   "source": [
    "### Nombre y Apellidos: \n",
    "\n",
    "# Chapter 1 - Load Data From CSV\n",
    "\n",
    "You must know how to load data before you can use it to train a machine learning model. When\n",
    "starting out, it is a good idea to stick with small in-memory datasets using standard file formats\n",
    "like comma separated value (.csv). In this tutorial you will discover how to load your data in\n",
    "Perl from scratch, including:\n",
    "\n",
    "* How to load a CSV file.\n",
    "* How to convert strings from a file to floating point numbers.\n",
    "* How to convert class values from a file to integers.\n",
    "\n",
    "Let’s get started.\n",
    "\n",
    "## 1.1 Description\n",
    "\n",
    "### 1.1.1 Comma Separated Values\n",
    "\n",
    "The standard file format for small datasets is Comma Separated Values or CSV. In its simplest\n",
    "form, CSV files are comprised of rows of data. Each row is divided into columns using a comma\n",
    "(,). In this tutorial, we are going to practice loading two different, standard machine learning\n",
    "datasets in CSV format.\n",
    "\n",
    "### 1.1.2 Pima Indians Diabetes Dataset\n",
    "\n",
    "In this tutorial we will use the Pima Indians Diabetes Dataset. This dataset involves the prediction of the onset of diabetes within 5 years. The baseline performance on the problem is approximately 65%. You can learn more about it in Appendix A, Section A.4. Download the dataset\n",
    "and save it into your current working directory with the filename pima-indians-diabetes.csv.\n",
    "\n",
    "### 1.1.3 Iris Flower Species Dataset\n",
    "\n",
    "In this tutorial we will also use the Iris Flower Species Dataset. This dataset involves the\n",
    "prediction of iris flower species. The baseline performance on the problem is approximately 26%.\n",
    "You can learn more about it in Appendix A, Section A.7. Download the dataset and save it\n",
    "into your current working directory with the filename iris.csv\n",
    "\n",
    "## 1.2 Tutorial\n",
    "\n",
    "This tutorial is divided into 3 parts:\n",
    "\n",
    "1. Utility functions.\n",
    "2. Load a file.\n",
    "3. Load a file and convert Strings to Floats.\n",
    "4. Load a file and convert Strings to Integers.\n",
    "\n",
    "These steps will provide the foundations you need to handle loading your own data.\n",
    "\n",
    "### 1.2.0. Utility functions\n",
    "\n",
    "We need a few utilities to simplify object-oriented programming in Jupyter notebooks. One of the challenges is that class definitions tend to be fairly long blocks of code. Notebook readability demands short code fragments, interspersed with explanations, a requirement incompatible with the style of programming common for Perl libraries. The first utility function allows us to register functions as methods in a class after the class has been created. In fact, we can do so even after we have created instances of the class! It allows us to split the implementation of a class into multiple code blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "926eed48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "Warning",
     "evalue": "Subroutine add_to_class redefined at reply input line 9.\n",
     "output_type": "error",
     "traceback": [
      "Subroutine add_to_class redefined at reply input line 9.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11078d72",
   "metadata": {},
   "source": [
    "We implement <b>add_to_class()</b> function inside a package named sml which stands for Statistical Machine Learning. This class will be expanded stepwisely throughout this course. The next step is to save the package sml into <b>sml.pm</b> in your Hard Drive in a visible Perl library path, such as /usr/local/share/perl5/5.34/x86_64-linux-thread-multi/, so that it can be loaded in every code. Find the path in your system and place the file sml.pm there. The function add_to_class() will allow registration of the functions needed by machine learning algorithms as methods of the class <b>sml</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0464c529",
   "metadata": {},
   "source": [
    "### 1.2.1 Load CSV File\n",
    "\n",
    "The first step is to load the CSV file. We will use the csv module that is a part of the standard\n",
    "library. The reader() function in the csv module takes a file as an argument.\n",
    "We will create a function called load csv() to wrap this behavior that will take a filename\n",
    "and return our dataset. We will represent the loaded dataset as a list of lists. The first list is\n",
    "a list of observations or rows, and the second list is the list of column values for a given row.\n",
    "Below is the complete function for loading a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "245ae389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fbbe6b5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "Warning",
     "evalue": "Subroutine load_csv redefined at reply input line 4.\n",
     "output_type": "error",
     "traceback": [
      "Subroutine load_csv redefined at reply input line 4.\n"
     ]
    }
   ],
   "source": [
    "# Defined in Section 1.2.1 Load CSV File\n",
    "# Function for loading a CSV\n",
    "# Load a CSV file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38517ae",
   "metadata": {},
   "source": [
    "Every time we defined a function for a machine learning algorithm, we need to include the variable $self as the first variable. It will contain the name of the class <b>sml</b>, followed by the variables that match with the obligatory parameters. The obligatory parameter variables values are directly received by their relative positions. Whereas the optional parameters are received as a dictionary, always including their names and respective values. To register the newly defined function <b>load_csv()</b> in the class sml, we just invoke <b>sml->add_to_class(funtion_name, \\&{'funtion_name'});</b> From that moment on, the function becomes a method of the sml class in memory. This allows for testing a newly implemented function. Once the function passes all the tests, it must be phisically embedded to the sml class. For that you must include the full function implementation as a method of the sml class, inside the file <b>sml.pm</b> in your local hard drive. This will allow you to construct your own statistical machine learning library for posterior use without the need of repeating the same codes everywhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c08c9657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "*sml::load_csv"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "Warning",
     "evalue": "Subroutine sml::load_csv redefined at reply input line 17.\n",
     "output_type": "error",
     "traceback": [
      "Subroutine sml::load_csv redefined at reply input line 17.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4adfcf3e",
   "metadata": {},
   "source": [
    "Now we can test this function by loading the Pima Indians dataset. Taking a peek at the first 5\n",
    "rows of the raw data file we can see the following:\n",
    "\n",
    "<table border=\"1\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Pregnancies</th>\n",
    "      <th>Glucose</th>\n",
    "      <th>Blood Pressure</th>\n",
    "      <th>Skin Thickness</th>\n",
    "      <th>Insulin</th>\n",
    "      <th>BMI</th>\n",
    "      <th>Diabetes Pedigree</th>\n",
    "      <th>Age</th>\n",
    "      <th>Outcome</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>6</td><td>148</td><td>72</td><td>35</td><td>0</td><td>33.6</td><td>0.627</td><td>50</td><td>1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>1</td><td>85</td><td>66</td><td>29</td><td>0</td><td>26.6</td><td>0.351</td><td>31</td><td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>8</td><td>183</td><td>64</td><td>0</td><td>0</td><td>23.3</td><td>0.672</td><td>32</td><td>1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>1</td><td>89</td><td>66</td><td>23</td><td>94</td><td>28.1</td><td>0.167</td><td>21</td><td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>0</td><td>137</td><td>40</td><td>35</td><td>168</td><td>43.1</td><td>2.288</td><td>33</td><td>1</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "<center>Peek at Pima Indians Diabetes dataset.</center>\n",
    "\n",
    "The data is numeric and phisically separated by commas in the file. Let’s use the new function and load the dataset. Once loaded we can report some simple details such as the number of rows and columns loaded. Putting all of this together, we get the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "844def9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data file ../data/pima-indians-diabetes.csv with 768 rows and 9 columns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pima-indians-diabetes dataset\n",
    "\n",
    "\n",
    "\n",
    "# Sample Output From Loading the Pima Indians Diabetes Dataset CSV File.\n",
    "# Loaded data file pima-indians-diabetes.csv with 768 rows and 9 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "658b9d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregnancies,Glucose,BloodPressure,SkinThickness,Insulin,BMI,DiabetesPedigreeFunction,Age,Outcome\r\n",
      "(\n",
      "  [6, 148, 72, 35, 0, 33.6, 0.627, 50, 1],\n",
      "  [1, 85, 66, 29, 0, 26.6, 0.351, 31, 0],\n",
      "  [8, 183, 64, 0, 0, 23.3, 0.672, 32, 1],\n",
      "  [1, 89, 66, 23, 94, 28.1, 0.167, 21, 0],\n",
      "  [0, 137, 40, 35, 168, 43.1, 2.288, 33, 1],\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Pregnancies,Glucose,BloodPressure,SkinThickness,Insulin,BMI,DiabetesPedigreeFunction,Age,Outcome\n",
    "# (\n",
    "#   [6, 148, 72, 35, 0, 33.6, 0.627, 50, 1],\n",
    "#   [1, 85, 66, 29, 0, 26.6, 0.351, 31, 0],\n",
    "#   [8, 183, 64, 0, 0, 23.3, 0.672, 32, 1],\n",
    "#   [1, 89, 66, 23, 94, 28.1, 0.167, 21, 0],\n",
    "#   [0, 137, 40, 35, 168, 43.1, 2.288, 33, 1],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7e269abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 148 72 35 0 33.6 0.627 50 1\n",
      "1 85 66 29 0 26.6 0.351 31 0\n",
      "8 183 64 0 0 23.3 0.672 32 1\n",
      "1 89 66 23 94 28.1 0.167 21 0\n",
      "0 137 40 35 168 43.1 2.288 33 1\n"
     ]
    }
   ],
   "source": [
    "# Alternative way to print a data sample:\n",
    "\n",
    "\n",
    "# 6 148 72 35 0 33.6 0.627 50 1\n",
    "# 1 85 66 29 0 26.6 0.351 31 0\n",
    "# 8 183 64 0 0 23.3 0.672 32 1\n",
    "# 1 89 66 23 94 28.1 0.167 21 0\n",
    "# 0 137 40 35 168 43.1 2.288 33 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ae6809a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\n",
      "  [6, 148, 72, 35, 0, 33.6, 0.627, 50, 1],\n",
      "  [1, 85, 66, 29, 0, 26.6, 0.351, 31, 0],\n",
      "  [8, 183, 64, 0, 0, 23.3, 0.672, 32, 1],\n",
      "  [1, 89, 66, 23, 94, 28.1, 0.167, 21, 0],\n",
      "  [0, 137, 40, 35, 168, 43.1, 2.288, 33, 1],\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also get the just the data without its header, thanks to 'wantarray()' command, \n",
    "# which differentiates between scalar and array contexts.\n",
    "\n",
    "# (\n",
    "#   [6, 148, 72, 35, 0, 33.6, 0.627, 50, 1],\n",
    "#   [1, 85, 66, 29, 0, 26.6, 0.351, 31, 0],\n",
    "#   [8, 183, 64, 0, 0, 23.3, 0.672, 32, 1],\n",
    "#   [1, 89, 66, 23, 94, 28.1, 0.167, 21, 0],\n",
    "#   [0, 137, 40, 35, 168, 43.1, 2.288, 33, 1],\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11c9533",
   "metadata": {},
   "source": [
    "### 1.2.2 Convert String into Floats\n",
    "\n",
    "Most, if not all machine learning algorithms prefer to work with numbers. Specifically, floating\n",
    "point numbers are preferred. Our code for loading a CSV file returns a dataset as a list of lists,\n",
    "but each value is a string. We can see this if we print out one record from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "04cc157c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row[0]: [5.1, 3.5, 1.4, 0.2, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Sample Output From Displaying One Row of Data\n",
    "# row[0]: [5.1, 3.5, 1.4, 0.2, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70330aa9",
   "metadata": {},
   "source": [
    "We can write a small function to convert specific columns of our loaded dataset to floating\n",
    "point values. Below is this function called str column to float(). It will convert a given\n",
    "column in the dataset to floating point values, careful to strip any whitespace from the value\n",
    "before making the conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "691bfd6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "*sml::str_column_to_float"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "Warning",
     "evalue": "Subroutine str_column_to_float redefined at reply input line 4.\n\nSubroutine sml::str_column_to_float redefined at reply input line 17.\n",
     "output_type": "error",
     "traceback": [
      "Subroutine str_column_to_float redefined at reply input line 4.\n\nSubroutine sml::str_column_to_float redefined at reply input line 17.\n"
     ]
    }
   ],
   "source": [
    "# Defined in Section 1.2.2 Convert String to Floats\n",
    "# Function For Converting String Data To Floats.\n",
    "# Convert string columns to float\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48261f4",
   "metadata": {},
   "source": [
    "We can test this function by combining it with our load CSV function above, and convert all\n",
    "of the numeric data in the Pima Indians dataset to floating point values. The complete example\n",
    "is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "252fc1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data file ../data/pima-indians-diabetes.csv with 768 rows and 9 columns.\n",
      "Header: Pregnancies,Glucose,BloodPressure,SkinThickness,Insulin,BMI,DiabetesPedigreeFunction,Age,Outcome\r\n",
      "Strings: [6, 148, 72, 35, 0, 33.6, 0.627, 50, 1]\n",
      "Floats: [\"6.0\", \"148.0\", \"72.0\", \"35.0\", \"0.0\", 33.6, 0.6, \"50.0\", 1]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Loaded data file ../data/pima-indians-diabetes.csv with 768 rows and 9 columns.\n",
    "# Header: Pregnancies,Glucose,BloodPressure,SkinThickness,Insulin,BMI,DiabetesPedigreeFunction,Age,Outcome\n",
    "# Strings: [6, 148, 72, 35, 0, 33.6, 0.627, 50, 1]\n",
    "# Floats: [\"6.0\", \"148.0\", \"72.0\", \"35.0\", \"0.0\", 33.6, 0.6, \"50.0\", 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a7f29a",
   "metadata": {},
   "source": [
    "### 1.2.3 Convert String into Integers\n",
    "\n",
    "The iris flowers dataset is like the Pima Indians dataset, in that the columns contain numeric\n",
    "data. The difference is the final column, traditionally used to hold the outcome or value to be\n",
    "predicted for a given row. The final column in the iris flowers data is the iris flower species as a\n",
    "string. For example, below are the first 5 rows of the raw dataset.\n",
    "\n",
    "<table border=\"1\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>SepalLengthCm</th>\n",
    "      <th>SepalWidthCm</th>\n",
    "      <th>PetalLengthCm</th>\n",
    "      <th>PetalWidthCm</th>\n",
    "      <th>Species</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>5.1</td>\n",
    "      <td>3.5</td>\n",
    "      <td>1.4</td>\n",
    "      <td>0.2</td>\n",
    "      <td>Iris-setosa</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>4.9</td>\n",
    "      <td>3.0</td>\n",
    "      <td>1.4</td>\n",
    "      <td>0.2</td>\n",
    "      <td>Iris-setosa</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>4.7</td>\n",
    "      <td>3.2</td>\n",
    "      <td>1.3</td>\n",
    "      <td>0.2</td>\n",
    "      <td>Iris-setosa</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>4.6</td>\n",
    "      <td>3.1</td>\n",
    "      <td>1.5</td>\n",
    "      <td>0.2</td>\n",
    "      <td>Iris-setosa</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>5.0</td>\n",
    "      <td>3.6</td>\n",
    "      <td>1.4</td>\n",
    "      <td>0.2</td>\n",
    "      <td>Iris-setosa</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "<center>Peek at Iris Flower Species dataset.</center>\n",
    "\n",
    "Some machine learning algorithms prefer all values to be numeric, including the outcome\n",
    "or predicted value. We can convert the class value in the iris flowers dataset to an integer by\n",
    "creating a map.\n",
    "1. First, we locate all of the unique class values, which happen to be: Iris-setosa,\n",
    "Iris-versicolor and Iris-virginica.\n",
    "2. Next, we assign an integer value to each, such as: 0, 1 and 2.\n",
    "3. Finally, we replace all occurrences of class string values with their corresponding integer\n",
    "values.\n",
    "Below is a function to do just that called str\\_column\\_to\\_int(). Like the previously\n",
    "introduced str\\_column\\_to\\_float() it operates on a single column in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e3f5cdba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "*sml::str_column_to_int"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defined in Section 1.2.3 Convert String to Integers\n",
    "# Function To Integer Encode String Class Values.\n",
    "# Convert string column to integer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36de972",
   "metadata": {},
   "source": [
    "We can test this new function in addition to the previous two functions for loading a CSV\n",
    "file and converting columns to floating point values. It also returns the dictionary mapping of\n",
    "class values to integer values, in case any users downstream want to convert predictions back to\n",
    "string values again. The example below loads the iris dataset then converts the first 3 columns\n",
    "to floats and the final column to integer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bd1aa53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data file ../data/iris.csv with 150 rows and 5 columns.\n",
      "\n",
      "Before label conversion into integers:\n",
      "\n",
      "SepalLengthCm,SepalWidthCm,PetalLengthCm,PetalWidthCm,Species\n",
      "(\n",
      "  [5.1, 3.5, 1.4, 0.2, \"Iris-setosa\"],\n",
      "  [4.9, \"3.0\", 1.4, 0.2, \"Iris-setosa\"],\n",
      "  [4.7, 3.2, 1.3, 0.2, \"Iris-setosa\"],\n",
      "  [4.6, 3.1, 1.5, 0.2, \"Iris-setosa\"],\n",
      "  [\"5.0\", 3.6, 1.4, 0.2, \"Iris-setosa\"],\n",
      ")\n",
      "\n",
      "After label conversion into integers:\n",
      "\n",
      "SepalLengthCm,SepalWidthCm,PetalLengthCm,PetalWidthCm,Species\n",
      "(\n",
      "  [5.1, 3.5, 1.4, 0.2, 0],\n",
      "  [4.9, \"3.0\", 1.4, 0.2, 0],\n",
      "  [4.7, 3.2, 1.3, 0.2, 0],\n",
      "  [4.6, 3.1, 1.5, 0.2, 0],\n",
      "  [\"5.0\", 3.6, 1.4, 0.2, 0],\n",
      ")\n",
      "\n",
      "Conversion dictionary: { \"Iris-setosa\" => 0, \"Iris-versicolor\" => 1, \"Iris-virginica\" => 2 }\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load iris dataset\n",
    "\n",
    "\n",
    "\n",
    "# Loaded data file ../data/iris.csv with 150 rows and 5 columns.\n",
    "\n",
    "# Before label conversion into integers:\n",
    "\n",
    "# SepalLengthCm,SepalWidthCm,PetalLengthCm,PetalWidthCm,Species\n",
    "# (\n",
    "#   [5.1, 3.5, 1.4, 0.2, \"Iris-setosa\"],\n",
    "#   [4.9, \"3.0\", 1.4, 0.2, \"Iris-setosa\"],\n",
    "#   [4.7, 3.2, 1.3, 0.2, \"Iris-setosa\"],\n",
    "#   [4.6, 3.1, 1.5, 0.2, \"Iris-setosa\"],\n",
    "#   [\"5.0\", 3.6, 1.4, 0.2, \"Iris-setosa\"],\n",
    "# )\n",
    "\n",
    "# After label conversion into integers:\n",
    "\n",
    "# SepalLengthCm,SepalWidthCm,PetalLengthCm,PetalWidthCm,Species\n",
    "# (\n",
    "#   [5.1, 3.5, 1.4, 0.2, 0],\n",
    "#   [4.9, \"3.0\", 1.4, 0.2, 0],\n",
    "#   [4.7, 3.2, 1.3, 0.2, 0],\n",
    "#   [4.6, 3.1, 1.5, 0.2, 0],\n",
    "#   [\"5.0\", 3.6, 1.4, 0.2, 0],\n",
    "# )\n",
    "\n",
    "# Conversion dictionary: { \"Iris-setosa\" => 0, \"Iris-versicolor\" => 1, \"Iris-virginica\" => 2 }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c35517",
   "metadata": {},
   "source": [
    "### 1.2.4 Convert Arrays into Tensors\n",
    "\n",
    "Once the arrays are fully preprocessed as numeric and all columns and rows are consistently filled, the conversion into tensor is straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "542874c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor:  <AI::MXNet::NDArray 768x9 @cpu(0)>\n",
      "Tensor:  \n",
      "[\n",
      " [      6     148      72      35       0    33.6     0.6      50       1]\n",
      " [      1      85      66      29       0    26.6     0.4      31       0]\n",
      " [      8     183      64       0       0    23.3     0.7      32       1]\n",
      " [      1      89      66      23      94    28.1     0.2      21       0]\n",
      " [      0     137      40      35     168    43.1     2.3      33       1]\n",
      "]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Tensor:  <AI::MXNet::NDArray 768x9 @cpu(0)>\n",
    "# Tensor:  \n",
    "# [\n",
    "#  [      6     148      72      35       0    33.6     0.6      50       1]\n",
    "#  [      1      85      66      29       0    26.6     0.4      31       0]\n",
    "#  [      8     183      64       0       0    23.3     0.7      32       1]\n",
    "#  [      1      89      66      23      94    28.1     0.2      21       0]\n",
    "#  [      0     137      40      35     168    43.1     2.3      33       1]\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d7cbd5",
   "metadata": {},
   "source": [
    "The next step is to obtain train and test partitions out of the dataset.\n",
    "\n",
    "## 1.3 Extensions\n",
    "\n",
    "You learned how to load CSV files and perform basic data conversions. Data loading can be\n",
    "a difficult task given the variety of data cleaning and conversion that may be required from\n",
    "problem to problem. There are many extensions that you could make to make these examples\n",
    "more robust to new and different data files. Below are just a few ideas you can consider\n",
    "researching and implementing yourself:\n",
    "\n",
    "* Detect and remove empty lines at the top or bottom of the file.\n",
    "* Detect and handle missing values in a column.\n",
    "* Detect and handle rows that do not match expectations for the rest of the file.\n",
    "\n",
    "## 1.4 Review\n",
    "\n",
    "In this tutorial, you discovered how you can load your machine learning data from scratch in\n",
    "Perl. Specifically, you learned:\n",
    "* How to load a CSV file into memory.\n",
    "* How to convert string values to floating point values.\n",
    "* How to convert a string class value into an integer encoding."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPerl 0.011",
   "language": "perl",
   "name": "iperl"
  },
  "language_info": {
   "file_extension": ".pl",
   "mimetype": "text/x-perl",
   "name": "perl",
   "version": "5.32.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
